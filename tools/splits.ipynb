{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T13:07:22.288523Z",
     "start_time": "2024-04-17T13:07:21.407030Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "ROW_WIDTH = 108\n",
    "\n",
    "corpus_statistics = []\n",
    "corpus_statistics_answers = []\n",
    "\n",
    "def separated_filter(row):\n",
    "    return len(row.answers) > 0 and len(row.answers) != len(range(row.answers[0], row.answers[-1] + 1))\n",
    "\n",
    "\n",
    "def print_row(values, width=15):\n",
    "    print(f'{values[0]:^{35}} |', ' | '.join([f'{it:^{width}}' for it in values[1:]]))\n",
    "    \n",
    "\n",
    "def add_latex_table_row(values, table):\n",
    "    indentation = '' if values[0] in ['all', 'German', 'English'] else '\\hspace{1em}'\n",
    "    table.append(f\"{indentation}{' & '.join([f'{it}' for it in values])} \\\\\\\\\")\n",
    "\n",
    "\n",
    "def print_split_stat(splits, get_value, name, digits=2):\n",
    "    values = [get_value(split) for split in splits]\n",
    "    rounded = [f'{value:.2f}' if digits > 0 else value for value in values]\n",
    "    print_row([name] + rounded)\n",
    "    add_latex_table_row([name] + rounded, table=corpus_statistics if digits == 0 else corpus_statistics_answers)\n",
    "\n",
    "\n",
    "def print_mean_std_stat(splits, get_column, name):\n",
    "    values = [[get_column(split).mean(), get_column(split).std()] for split in splits]\n",
    "    rounded_print = [f'{value[0]:.2f} ({value[1]:.2f})' for value in values]\n",
    "    rounded_latex = [f'{value[0]:.2f} \\\\textcolor{{gray}}{{\\scriptsize $\\pm$ {value[1]:.2f}}}' for value in values]\n",
    "    print_row([name] + rounded_print)\n",
    "    add_latex_table_row([name] + rounded_latex, table=corpus_statistics_answers)\n",
    "    \n",
    "\n",
    "def load_split(name, language):\n",
    "    split_path = f'../datasets/splits/{language}/{name}_{language}.json'\n",
    "    return pd.DataFrame(json.load(open(split_path, 'r')))\n",
    "\n",
    "\n",
    "def prepare_split(name, language):\n",
    "    split_df = load_split(name, language)\n",
    "    split_df['answer_count'] = split_df.apply(lambda x: len(x.answers), axis=1)\n",
    "    split_df['sentences'] = split_df.apply(lambda x: x.context.count('\\n') + 1, axis=1)\n",
    "    split_df['chars'] = split_df.apply(lambda x: len(x.context), axis=1)\n",
    "    split_df['question_word'] = split_df.apply(lambda x: x.question.split(' ')[0], axis=1)\n",
    "    split_df['question_chars'] = split_df.apply(lambda x: len(x.question), axis=1)\n",
    "    split_df['chars_per_sentence'] = split_df.apply(lambda x: x.chars / x.sentences, axis=1)\n",
    "    split_df['sentences_per_context'] = split_df.apply(lambda x: x.sentences, axis=1)\n",
    "    split_df['answers_per_sentence'] = split_df.apply(lambda x: x.answer_count / x.sentences, axis=1)\n",
    "    \n",
    "    contexts_df = split_df[split_df.duplicated(subset=['pageId']) != True]\n",
    "\n",
    "    if language is None:\n",
    "        return [split_df, contexts_df]\n",
    "    elif language == 'de':\n",
    "        de_split_df = split_df[(split_df.language == 'de') & (split_df.sourceLanguage != 'en')]\n",
    "        de_contexts_df = de_split_df[de_split_df.duplicated(subset=['pageId']) != True]\n",
    "        return [de_split_df, de_contexts_df]\n",
    "    else:\n",
    "        en_split_df = split_df[(split_df.language == 'en') & (split_df.sourceLanguage != 'de')]\n",
    "        en_contexts_df = en_split_df[en_split_df.duplicated(subset=['pageId']) != True]\n",
    "        return [en_split_df, en_contexts_df]\n",
    "\n",
    "\n",
    "def analyze_split_language_corpus(language):\n",
    "    train = prepare_split('train', language)\n",
    "    dev = prepare_split('dev', language)\n",
    "    test = prepare_split('test', language)\n",
    "    total = [pd.concat([train[i], dev[i], test[i]]) for i in range(2)]\n",
    "    splits = [train, dev, test, total]\n",
    "    \n",
    "    # Formatting\n",
    "    if language is not None:\n",
    "        corpus_statistics.append('\\midrule')\n",
    "        corpus_statistics_answers.append('\\midrule')\n",
    "    add_latex_table_row(['German' if language == 'de' else 'English' if language is not None else 'all', '', '', '', ''], table=corpus_statistics_answers)\n",
    "    \n",
    "    # Overall Stats\n",
    "    print_split_stat(splits, lambda dfs: len(dfs[0]), 'German' if language == 'de' else 'English' if language is not None else 'all', 0)\n",
    "    print_split_stat(splits, lambda dfs: len(dfs[0][dfs[0].answers.str.len() == 0]), 'No Answer', 0)\n",
    "    print_split_stat(splits, lambda dfs: len(dfs[0][dfs[0].apply(separated_filter, axis=1)]), 'Divided Answer', 0)\n",
    "    \n",
    "    # Corpus Stats\n",
    "    print('-' * ROW_WIDTH)\n",
    "    print_split_stat(splits, lambda dfs: len(dfs[0]) / len(dfs[1]), 'Questions/Document')\n",
    "    # TODO sum vs single?\n",
    "    # print_split_stat(splits, lambda dfs: dfs[1].chars.sum() / dfs[1].sentences.sum(), 'Chars/Sentence (sum)')\n",
    "    print_mean_std_stat(splits, lambda dfs: dfs[1].chars_per_sentence, 'Chars/Sentence')\n",
    "    print_mean_std_stat(splits, lambda dfs: dfs[1].sentences, 'Sentences/Document')\n",
    "\n",
    "    # Answer Stats\n",
    "    print('-' * ROW_WIDTH)\n",
    "    corpus_statistics_answers.append('\\midrule')\n",
    "    print_mean_std_stat(splits, lambda dfs: dfs[0].jaccard, 'Agreement')\n",
    "    # TODO w. vs w/o. answers?\n",
    "    print_mean_std_stat(splits, lambda dfs: dfs[0].answer_count, 'Answers/Question')\n",
    "    # print_mean_std_stat(splits, lambda dfs: dfs[0][dfs[0].answer_count > 0].answer_count, 'Answers/Question (w/o no answers)')\n",
    "    # TODO sum vs single?\n",
    "    # print_split_stat(splits, lambda dfs: dfs[0].answer_count.sum() / dfs[0].sentences.sum(), 'Answers/Sentence % (w no answers) (sum)')\n",
    "    # TODO w. vs w/o. answers?\n",
    "    print_mean_std_stat(splits, lambda dfs: dfs[0].answers_per_sentence, 'Answers/Sentence')\n",
    "    # print_mean_std_stat(splits, lambda dfs: dfs[0][dfs[0].answer_count > 0].answers_per_sentence, 'Answers/Sentence (w/o no answers)')\n",
    "\n",
    "    # Question Stats\n",
    "    print('-' * ROW_WIDTH)\n",
    "    corpus_statistics_answers.append('\\midrule')\n",
    "    print_mean_std_stat(splits, lambda dfs: dfs[0].question_chars, 'Chars/Question')\n",
    "\n",
    "\n",
    "def analyze_split_corpus():\n",
    "    print_row(['', 'train', 'dev', 'test', 'total'])\n",
    "    for language in [None, 'de', 'en']:\n",
    "        print('#' * ROW_WIDTH)\n",
    "        # TODO english vs german w. english source\n",
    "        analyze_split_language_corpus(language)\n",
    "\n",
    "    train = prepare_split('train', None)\n",
    "    dev = prepare_split('dev', None)\n",
    "    test = prepare_split('test', None)\n",
    "    total = [pd.concat([train[i], dev[i], test[i]]) for i in range(2)]\n",
    "    print()\n",
    "    print('#' * ROW_WIDTH)\n",
    "    print('Question words')\n",
    "    print('\\n'.join([f'{key}: {value}' for key, value in total[0].question_word.value_counts()[total[0].question_word.value_counts() > 5].items()]))\n",
    "    print(f'Other {total[0].question_word.value_counts()[total[0].question_word.value_counts() <= 5].sum()}')\n",
    "    \n",
    "    table_file = open('./resources/corpus.txt', 'w')\n",
    "    table_file.write('\\n'.join(corpus_statistics))\n",
    "\n",
    "    table_file = open('./resources/corpus_answers.txt', 'w')\n",
    "    table_file.write('\\n'.join(corpus_statistics_answers))\n",
    "\n",
    "\n",
    "analyze_split_corpus()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    |      train      |       dev       |      test       |      total     \n",
      "############################################################################################################\n",
      "                all                 |       461       |       193       |       252       |       906      \n",
      "             No Answer              |       81        |       38        |       55        |       174      \n",
      "          Divided Answer            |       76        |       31        |       44        |       151      \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "        Questions/Document          |      1.50       |      1.45       |      1.43       |      1.47      \n",
      "          Chars/Sentence            |  61.96 (17.51)  |  63.10 (15.63)  |  62.52 (16.79)  |  62.36 (16.90) \n",
      "        Sentences/Document          |  25.94 (18.18)  |  27.19 (16.11)  |  26.43 (16.56)  |  26.35 (17.28) \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "             Agreement              |   0.87 (0.18)   |   0.85 (0.18)   |   0.86 (0.19)   |   0.86 (0.18)  \n",
      "         Answers/Question           |   5.11 (5.82)   |   5.14 (5.43)   |   5.00 (6.29)   |   5.09 (5.87)  \n",
      "         Answers/Sentence           |   0.26 (0.28)   |   0.23 (0.26)   |   0.25 (0.27)   |   0.25 (0.27)  \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "          Chars/Question            |  59.94 (16.97)  |  60.64 (17.24)  |  60.79 (16.63)  |  60.33 (16.92) \n",
      "############################################################################################################\n",
      "              German                |       338       |       143       |       185       |       666      \n",
      "             No Answer              |       63        |       30        |       43        |       136      \n",
      "          Divided Answer            |       66        |       27        |       38        |       131      \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "        Questions/Document          |      1.65       |      1.59       |      1.58       |      1.62      \n",
      "          Chars/Sentence            |  58.62 (15.93)  |  61.74 (16.32)  |  61.96 (17.25)  |  60.25 (16.44) \n",
      "        Sentences/Document          |  27.16 (20.11)  |  27.96 (15.87)  |  26.91 (17.88)  |  27.26 (18.59) \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "             Agreement              |   0.86 (0.18)   |   0.86 (0.18)   |   0.86 (0.18)   |   0.86 (0.18)  \n",
      "         Answers/Question           |   5.37 (6.09)   |   5.57 (5.89)   |   5.29 (6.84)   |   5.39 (6.26)  \n",
      "         Answers/Sentence           |   0.28 (0.29)   |   0.25 (0.27)   |   0.27 (0.28)   |   0.27 (0.28)  \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "          Chars/Question            |  57.85 (15.68)  |  58.91 (17.21)  |  59.61 (16.45)  |  58.56 (16.23) \n",
      "############################################################################################################\n",
      "              English               |       123       |       50        |       67        |       240      \n",
      "             No Answer              |       18        |        8        |       12        |       38       \n",
      "          Divided Answer            |       10        |        4        |        6        |       20       \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "        Questions/Document          |      1.19       |      1.16       |      1.14       |      1.17      \n",
      "          Chars/Sentence            |  68.60 (18.66)  |  65.96 (13.84)  |  63.62 (15.93)  |  66.61 (17.04) \n",
      "        Sentences/Document          |  23.51 (13.30)  |  25.58 (16.68)  |  25.49 (13.68)  |  24.52 (14.14) \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "             Agreement              |   0.87 (0.19)   |   0.85 (0.19)   |   0.86 (0.19)   |   0.86 (0.19)  \n",
      "         Answers/Question           |   4.41 (4.98)   |   3.90 (3.62)   |   4.19 (4.39)   |   4.24 (4.55)  \n",
      "         Answers/Sentence           |   0.23 (0.23)   |   0.20 (0.21)   |   0.22 (0.24)   |   0.22 (0.23)  \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "          Chars/Question            |  65.69 (18.98)  |  65.60 (16.52)  |  64.07 (16.80)  |  65.22 (17.84) \n",
      "\n",
      "############################################################################################################\n",
      "Question words\n",
      "Welche: 244\n",
      "Was: 185\n",
      "Wie: 171\n",
      "Wo: 93\n",
      "Wer: 59\n",
      "FÃ¼r: 25\n",
      "Gibt: 17\n",
      "Wann: 15\n",
      "Welches: 13\n",
      "An: 12\n",
      "In: 11\n",
      "Ist: 10\n",
      "Other 51\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
