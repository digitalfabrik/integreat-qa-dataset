{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T13:02:50.168307Z",
     "start_time": "2024-04-18T13:02:48.390069Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "ROW_WIDTH = 108\n",
    "\n",
    "corpus_statistics = []\n",
    "corpus_statistics_answers = []\n",
    "\n",
    "def separated_filter(row):\n",
    "    return len(row.answers) > 0 and len(row.answers) != len(range(row.answers[0], row.answers[-1] + 1))\n",
    "\n",
    "\n",
    "def print_row(values, width=15):\n",
    "    print(f'{values[0]:^{35}} |', ' | '.join([f'{it:^{width}}' for it in values[1:]]))\n",
    "    \n",
    "\n",
    "def add_latex_table_row(values, table):\n",
    "    indentation = ''\n",
    "    table.append(f\"{indentation} {' & '.join([f'{it}' for it in values])} \\\\\\\\\")\n",
    "\n",
    "\n",
    "def print_split_stat(splits, get_value, name, digits=2, prefix=''):\n",
    "    values = [get_value(split) for split in splits]\n",
    "    rounded = [f'{value:.2f}' if digits > 0 else value for value in values]\n",
    "    print_row([name] + rounded)\n",
    "    add_latex_table_row([prefix, name] + rounded, table=corpus_statistics_answers)\n",
    "\n",
    "\n",
    "def print_percentage_stat(splits, get_column, name):\n",
    "    indentation = '\\hspace{1em}' if name in ['No Answer', 'Contiguous Answer', 'Non-Contiguous Answer'] else ''\n",
    "    values = [[get_column(split)[0], 100 * get_column(split)[0] / get_column(split)[1]] for split in splits]\n",
    "    rounded_print = [f'{value[0]} ({value[1]:.2f})' for value in values]\n",
    "    rounded_latex = [f'{value[0]} \\\\textcolor{{gray}}{{\\scriptsize ({value[1]:.0f}\\%)}}' for value in values]\n",
    "    print_row([name] + rounded_print)\n",
    "    add_latex_table_row(['', f'{indentation}{name}'] + rounded_latex, table=corpus_statistics_answers)\n",
    "\n",
    "\n",
    "def print_mean_std_stat(splits, get_column, name):\n",
    "    values = [[get_column(split).mean(), get_column(split).std()] for split in splits]\n",
    "    rounded_print = [f'{value[0]:.2f} ({value[1]:.2f})' for value in values]\n",
    "    rounded_latex = [f'{value[0]:.2f} \\\\textcolor{{gray}}{{\\scriptsize $\\pm$ {value[1]:.2f}}}' for value in values]\n",
    "    print_row([name] + rounded_print)\n",
    "    add_latex_table_row(['', name] + rounded_latex, table=corpus_statistics_answers)\n",
    "    \n",
    "\n",
    "def load_split(name, language):\n",
    "    if language is None:\n",
    "        return load_split(name, 'de')\n",
    "    split_path = f'../datasets/splits/{language}/{name}_{language}.json'\n",
    "    return pd.DataFrame(json.load(open(split_path, 'r')))\n",
    "\n",
    "\n",
    "def prepare_split(name, language):\n",
    "    split_df = load_split(name, language)\n",
    "    split_df['answer_count'] = split_df.apply(lambda x: len(x.answers), axis=1)\n",
    "    split_df['sentences'] = split_df.apply(lambda x: x.context.count('\\n') + 1, axis=1)\n",
    "    split_df['chars'] = split_df.apply(lambda x: len(x.context), axis=1)\n",
    "    split_df['question_word'] = split_df.apply(lambda x: x.question.split(' ')[0], axis=1)\n",
    "    split_df['question_chars'] = split_df.apply(lambda x: len(x.question), axis=1)\n",
    "    split_df['chars_per_sentence'] = split_df.apply(lambda x: x.chars / x.sentences, axis=1)\n",
    "    split_df['sentences_per_context'] = split_df.apply(lambda x: x.sentences, axis=1)\n",
    "    split_df['answers_per_sentence'] = split_df.apply(lambda x: x.answer_count / x.sentences, axis=1)\n",
    "    \n",
    "    contexts_df = split_df[split_df.duplicated(subset=['pageId']) != True]\n",
    "\n",
    "    if language is None:\n",
    "        return [split_df, contexts_df]\n",
    "    elif language == 'de':\n",
    "        de_split_df = split_df[(split_df.language == 'de') & (split_df.sourceLanguage != 'en')]\n",
    "        de_contexts_df = de_split_df[de_split_df.duplicated(subset=['pageId']) != True]\n",
    "        return [de_split_df, de_contexts_df]\n",
    "    else:\n",
    "        en_split_df = split_df[(split_df.language == 'en') & (split_df.sourceLanguage != 'de')]\n",
    "        en_contexts_df = en_split_df[en_split_df.duplicated(subset=['pageId']) != True]\n",
    "        return [en_split_df, en_contexts_df]\n",
    "\n",
    "\n",
    "def analyze_split_language_corpus(language):\n",
    "    train = prepare_split('train', language)\n",
    "    dev = prepare_split('dev', language)\n",
    "    test = prepare_split('test', language)\n",
    "    total = [pd.concat([train[i], dev[i], test[i]]) for i in range(2)]\n",
    "    splits = [train, dev, test, total]\n",
    "    \n",
    "    full_language = 'German' if language == 'de' else 'English' if language is not None else 'All' \n",
    "    \n",
    "    # Formatting\n",
    "    corpus_statistics.append('\\midrule')\n",
    "    corpus_statistics_answers.append('\\midrule')\n",
    "    # add_latex_table_row(['German' if language == 'de' else 'English' if language is not None else 'all', '', '', '', '', ''], table=corpus_statistics_answers)\n",
    "    \n",
    "    # Overall Stats\n",
    "    print_split_stat(splits, lambda dfs: len(dfs[0]), 'Questions', 0, prefix=full_language)\n",
    "    print_percentage_stat(splits, lambda dfs: [len(dfs[0][dfs[0].answers.str.len() == 0]), len(dfs[0])], 'No Answer')\n",
    "    print_percentage_stat(splits, lambda dfs: [len(dfs[0]) - len(dfs[0][dfs[0].answers.str.len() == 0]) - len(dfs[0][dfs[0].apply(separated_filter, axis=1)]), len(dfs[0])], 'Contiguous Answer')\n",
    "    print_percentage_stat(splits, lambda dfs: [len(dfs[0][dfs[0].apply(separated_filter, axis=1)]), len(dfs[0])], 'Non-Contiguous Answer')\n",
    "    \n",
    "    if language is not None:\n",
    "        # Corpus Stats\n",
    "        print('-' * ROW_WIDTH)\n",
    "        print_split_stat(splits, lambda dfs: len(dfs[1]), 'Documents', 0)\n",
    "        print_split_stat(splits, lambda dfs: len(dfs[0]) / len(dfs[1]), 'Questions/Document')\n",
    "        # TODO sum vs single?\n",
    "        # print_split_stat(splits, lambda dfs: dfs[1].chars.sum() / dfs[1].sentences.sum(), 'Chars/Sentence (sum)')\n",
    "        print_mean_std_stat(splits, lambda dfs: dfs[1].sentences, 'Sentences/Document')\n",
    "        print_mean_std_stat(splits, lambda dfs: dfs[1].chars_per_sentence, 'Chars/Sentence')\n",
    "        print_mean_std_stat(splits, lambda dfs: dfs[0].question_chars, 'Chars/Question')\n",
    "\n",
    "        # Answer Stats\n",
    "        print('-' * ROW_WIDTH)\n",
    "        print_mean_std_stat(splits, lambda dfs: dfs[0].jaccard, 'Agreement (Jaccard)')\n",
    "        # TODO w. vs w/o. answers?\n",
    "        print_mean_std_stat(splits, lambda dfs: dfs[0].answer_count, 'Answer Sentences/Question')\n",
    "        # print_mean_std_stat(splits, lambda dfs: dfs[0][dfs[0].answer_count > 0].answer_count, 'Answers/Question (w/o no answers)')\n",
    "        # TODO sum vs single?\n",
    "        # print_split_stat(splits, lambda dfs: dfs[0].answer_count.sum() / dfs[0].sentences.sum(), 'Answers/Sentence % (w no answers) (sum)')\n",
    "        # TODO w. vs w/o. answers?\n",
    "        print_mean_std_stat(splits, lambda dfs: dfs[0].answers_per_sentence, 'Answers Sentences/Total Sentences')\n",
    "        # print_mean_std_stat(splits, lambda dfs: dfs[0][dfs[0].answer_count > 0].answers_per_sentence, 'Answers/Sentence (w/o no answers)')\n",
    "\n",
    "\n",
    "def analyze_split_corpus():\n",
    "    print_row(['', 'train', 'dev', 'test', 'total'])\n",
    "    corpus_statistics_answers.append('\\\\toprule')\n",
    "    add_latex_table_row(['', '', 'train', 'dev', 'test', 'total'], corpus_statistics_answers)\n",
    "    \n",
    "    for language in ['de', 'en', None]:\n",
    "        print('#' * ROW_WIDTH)\n",
    "        # TODO english vs german w. english source\n",
    "        analyze_split_language_corpus(language)\n",
    "        \n",
    "    corpus_statistics_answers.append('\\\\bottomrule')\n",
    "\n",
    "    train = prepare_split('train', None)\n",
    "    dev = prepare_split('dev', None)\n",
    "    test = prepare_split('test', None)\n",
    "    total = [pd.concat([train[i], dev[i], test[i]]) for i in range(2)]\n",
    "    print()\n",
    "    print('#' * ROW_WIDTH)\n",
    "    print('Question words')\n",
    "    print('\\n'.join([f'{key}: {value}' for key, value in total[0].question_word.value_counts()[total[0].question_word.value_counts() > 5].items()]))\n",
    "    print(f'Other {total[0].question_word.value_counts()[total[0].question_word.value_counts() <= 5].sum()}')\n",
    "    \n",
    "    table_file = open('./resources/corpus.txt', 'w')\n",
    "    table_file.write('\\n'.join(corpus_statistics))\n",
    "\n",
    "    table_file = open('./resources/corpus_answers.txt', 'w')\n",
    "    table_file.write('\\n'.join(corpus_statistics_answers))\n",
    "\n",
    "\n",
    "analyze_split_corpus()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    |      train      |       dev       |      test       |      total     \n",
      "############################################################################################################\n",
      "             Questions              |       338       |       143       |       185       |       666      \n",
      "             No Answer              |   63 (18.64)    |   30 (20.98)    |   43 (23.24)    |   136 (20.42)  \n",
      "         Contiguous Answer          |   209 (61.83)   |   86 (60.14)    |   104 (56.22)   |   399 (59.91)  \n",
      "       Non-Contiguous Answer        |   66 (19.53)    |   27 (18.88)    |   38 (20.54)    |   131 (19.67)  \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "             Documents              |       205       |       90        |       117       |       412      \n",
      "        Questions/Document          |      1.65       |      1.59       |      1.58       |      1.62      \n",
      "        Sentences/Document          |  27.16 (20.11)  |  27.96 (15.87)  |  26.91 (17.88)  |  27.26 (18.59) \n",
      "          Chars/Sentence            |  58.62 (15.93)  |  61.74 (16.32)  |  61.96 (17.25)  |  60.25 (16.44) \n",
      "          Chars/Question            |  57.85 (15.68)  |  58.91 (17.21)  |  59.61 (16.45)  |  58.56 (16.23) \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "        Agreement (Jaccard)         |   0.86 (0.18)   |   0.86 (0.18)   |   0.86 (0.18)   |   0.86 (0.18)  \n",
      "     Answer Sentences/Question      |   5.37 (6.09)   |   5.57 (5.89)   |   5.29 (6.84)   |   5.39 (6.26)  \n",
      " Answers Sentences/Total Sentences  |   0.28 (0.29)   |   0.25 (0.27)   |   0.27 (0.28)   |   0.27 (0.28)  \n",
      "############################################################################################################\n",
      "             Questions              |       123       |       50        |       67        |       240      \n",
      "             No Answer              |   18 (14.63)    |    8 (16.00)    |   12 (17.91)    |   38 (15.83)   \n",
      "         Contiguous Answer          |   95 (77.24)    |   38 (76.00)    |   49 (73.13)    |   182 (75.83)  \n",
      "       Non-Contiguous Answer        |    10 (8.13)    |    4 (8.00)     |    6 (8.96)     |    20 (8.33)   \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "             Documents              |       103       |       43        |       59        |       205      \n",
      "        Questions/Document          |      1.19       |      1.16       |      1.14       |      1.17      \n",
      "        Sentences/Document          |  23.51 (13.30)  |  25.58 (16.68)  |  25.49 (13.68)  |  24.52 (14.14) \n",
      "          Chars/Sentence            |  65.28 (18.22)  |  61.74 (12.72)  |  60.48 (15.30)  |  63.16 (16.45) \n",
      "          Chars/Question            |  59.46 (15.98)  |  56.48 (13.22)  |  56.51 (14.72)  |  58.01 (15.11) \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "        Agreement (Jaccard)         |   0.87 (0.19)   |   0.85 (0.19)   |   0.86 (0.19)   |   0.86 (0.19)  \n",
      "     Answer Sentences/Question      |   4.41 (4.98)   |   3.90 (3.62)   |   4.19 (4.39)   |   4.24 (4.55)  \n",
      " Answers Sentences/Total Sentences  |   0.23 (0.23)   |   0.20 (0.21)   |   0.22 (0.24)   |   0.22 (0.23)  \n",
      "############################################################################################################\n",
      "             Questions              |       461       |       193       |       252       |       906      \n",
      "             No Answer              |   81 (17.57)    |   38 (19.69)    |   55 (21.83)    |   174 (19.21)  \n",
      "         Contiguous Answer          |   304 (65.94)   |   124 (64.25)   |   153 (60.71)   |   581 (64.13)  \n",
      "       Non-Contiguous Answer        |   76 (16.49)    |   31 (16.06)    |   44 (17.46)    |   151 (16.67)  \n",
      "\n",
      "############################################################################################################\n",
      "Question words\n",
      "Welche: 244\n",
      "Was: 185\n",
      "Wie: 171\n",
      "Wo: 93\n",
      "Wer: 59\n",
      "FÃ¼r: 25\n",
      "Gibt: 17\n",
      "Wann: 15\n",
      "Welches: 13\n",
      "An: 12\n",
      "In: 11\n",
      "Ist: 10\n",
      "Other 51\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
